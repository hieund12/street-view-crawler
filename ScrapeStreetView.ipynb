{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Generates a random file with coordinates from a defined bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "\n",
    "output = open(\"places/test1.csv\", \"w\")\n",
    "output.write('latitude'+','+'longitude'+\"\\n\")\n",
    "\n",
    "def newpoint():\n",
    "    # insert your own bounding box, remember to follow the \n",
    "    # (latitude,latitude),(longitude,longitude) scheme\n",
    "    return uniform(44.48,44.50), uniform(11.3043, 11.3718)\n",
    "\n",
    "# set the number of coordinates in xrange and saves a csv file\n",
    "points = (newpoint() for x in range(500))\n",
    "for point in points:\n",
    "    #print point[0],point[1]\n",
    "    output.write(str(point[0])+\",\"+str(point[1])+\"\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "output.close()\n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From csv file downloads google street view images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import urllib\n",
    "import urllib.request\n",
    "import time\n",
    "\n",
    "# prende il file csv con le coordinate e lo mette in array location\n",
    "locations = []\n",
    "with open('places/test1.csv', 'rt') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "\n",
    "    is_first_row = True\n",
    "    for row in reader:\n",
    "        # Skip the first row.\n",
    "        if is_first_row:\n",
    "            is_first_row = False\n",
    "            continue\n",
    "\n",
    "        lat, lon = float(row[0]), float(row[1])\n",
    "        location = (lat, lon)\n",
    "        locations.append(location)\n",
    "\n",
    "# prepara url e mettere api_key\n",
    "api_key = \"AIzaSyAC9P4Njf_yRogkp0M-cPpWr5Op_r6hvg4\"\n",
    "base_url = \"https://maps.googleapis.com/maps/api/streetview?size=640x400&location={0},{1}&fov=90&heading={2}&pitch=10&key=\" + api_key\n",
    "\n",
    "row = 2\n",
    "headings = [0,45, 90,135 ,175,220, 265,310,355]\n",
    "\n",
    "output = open(\"data/database.csv\", \"w\")\n",
    "\n",
    "# fa loop delle locations e in base ai gradi sopra salva screen\n",
    "for location in locations:\n",
    "    for direction in headings:\n",
    "        # crea url per google\n",
    "        lat, lon = location\n",
    "        url = base_url.format(lat, lon, direction)\n",
    "\n",
    "        # crea il file ex: location-2-90.jpg.\n",
    "        filename = \"img/location-{0}-{1}.jpg\".format(row, direction)\n",
    "        output.write(filename+',')\n",
    "\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "        print (\"Got %s\" % (filename,))\n",
    "\n",
    "    time.sleep(0.5)\n",
    "    # Increment the row to correlate with the Excel file.\n",
    "    row += 1\n",
    "    print (location)\n",
    "    output.write(str(lat)+','+str(lon)+',')\n",
    "\n",
    "    output.write(\"\\n\")\n",
    "\n",
    "\n",
    "    \n",
    "    #break\n",
    "output.close()\n",
    "print (\"fine\")  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# tensorflow embeddings are added to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "from imutils import paths\n",
    "from orangecontrib.imageanalytics.image_embedder import ImageEmbedder\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.calibration import CalibratedClassifierCV, _CalibratedClassifier\n",
    "import time\n",
    "from natsort import natsorted, ns\n",
    "\n",
    "image_file_paths = list(paths.list_images('/Users/sinanatra/Documents/GitHub/street-view-crawler/machine-learning'))\n",
    "chunk_size = 100\n",
    "embeddings = []\n",
    "start_time = time.time()\n",
    "skipped = []\n",
    "\n",
    "for l in range(0, len(image_file_paths), chunk_size):\n",
    "    \n",
    "    chunk = image_file_paths[l:l + chunk_size]\n",
    "    sort = natsorted(chunk, alg=ns.IGNORECASE)  \n",
    "    print(\"chunking\")\n",
    "    \n",
    "    with ImageEmbedder(model='inception-v3', layer='penultimate') as embedder:\n",
    "        embeddings.extend([el for el in embedder(chunk) if type(el) is numpy.ndarray])\n",
    "        \n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    \n",
    "print('done')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Training and cross validation then dumps a .pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn import datasets, linear_model, cross_validation, grid_search\n",
    "from sklearn import svm\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "X = np.array(embeddings)\n",
    "y = np.array([file_name.split('/')[-2] for file_name in image_file_paths if file_name not in skipped])\n",
    "kf_total = cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True)\n",
    "for train, test in kf_total:\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "\n",
    "    classifier = svm.SVC(C=100, random_state=42,probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(precision_recall_fscore_support(y_test, y_pred, average='micro'))\n",
    "    print(precision_recall_fscore_support(y_test, y_pred, average='macro'))\n",
    "    print()\n",
    "print(\"done.\")\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "     \n",
    "save_classifier = open(\"tag.pickle\",\"wb\")\n",
    "pickle.dump(classifier,save_classifier)\n",
    "save_classifier.close()    \n",
    "print (\"classifier saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the pickle it saves a csv file and moves tested images in new folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from imutils import paths\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "from sklearn.externals import joblib\n",
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    " \n",
    "from orangecontrib.imageanalytics.image_embedder import ImageEmbedder\n",
    "import numpy\n",
    "import time\n",
    "from natsort import natsorted, ns\n",
    "\n",
    "model_f=open(\"tag.pickle\",\"rb\")\n",
    "classifier = pickle.load(model_f)\n",
    "model_f.close()\n",
    "\n",
    "cartellone = {\n",
    "    'tag': 'divisione/TAG/tag',\n",
    "    'empty': 'divisione/TAG/empty',    \n",
    "}\n",
    "\n",
    "# creating my folders\n",
    "for imageType, dirPath in cartellone.items():\n",
    "    if not os.path.exists(dirPath):\n",
    "        print('creating')\n",
    "        os.makedirs(dirPath)\n",
    "    \n",
    "test_img = list(paths.list_images(\"/Users/sinanatra/Documents/GitHub/street-view-crawler/img\"))\n",
    "\n",
    "# creating a  map pathImage => typeImage\n",
    "mapPath = {}\n",
    "\n",
    "for imagePath in paths.list_images(\"/Users/sinanatra/Documents/GitHub/street-view-crawler/img\"):\n",
    "    imageType = imagePath.split(\"/\")[-1].split(\".\")[0]            \n",
    "    mapPath[imagePath] = imageType\n",
    "    \n",
    "    \n",
    "test_img = natsorted(test_img, alg=ns.IGNORECASE)\n",
    "chunk_size = 1\n",
    "embeddings = []\n",
    "start_time = time.time()\n",
    "skipped = []\n",
    "output = open(\"tag.csv\", \"w\")\n",
    "\n",
    "\n",
    "for l in range(0, len(test_img), chunk_size):\n",
    "    chunk = test_img[l:l + chunk_size]\n",
    "\n",
    "    local = chunk[0].split(\"/\")\n",
    "    local = local[len(local)-1]\n",
    "    print (local)\n",
    "    \n",
    "    output.write(local+\";\")\n",
    "\n",
    "    \n",
    "    try:        \n",
    "        with ImageEmbedder(model='inception-v3', layer='penultimate') as embedder:\n",
    "            elements = embedder(chunk)\n",
    "            predicted = classifier.predict(elements)\n",
    "            y_proba = classifier.predict_proba(elements)\n",
    "            \n",
    "            output.write(str(predicted[0])+';')\n",
    "            for texturepercent in y_proba:\n",
    "                print()\n",
    "\n",
    "                print(';     '.join(map(str,  np.around(texturepercent*100))))\n",
    "                output.write(';'.join(map(str, np.around(texturepercent*100))))\n",
    "                #output.write(\"\\n\")\n",
    "\n",
    "            shutil.copy(chunk[0],cartellone[predicted[0]])\n",
    "            print (chunk)\n",
    "            output.write(\"\\n\")\n",
    "            print(predicted)\n",
    "        for i in range(len(elements)):\n",
    "            \n",
    "            # loading one by one (= 1)\n",
    "            el = elements[i]\n",
    "            if type(el) is not numpy.ndarray:\n",
    "                output.write(\"\\n\")\n",
    "    \n",
    "                # filtering damaged images\n",
    "                skipped.append(chunk[i])\n",
    "\n",
    "                continue\n",
    "            \n",
    "            embeddings.append(el)  \n",
    "            \n",
    "    except Exception as e:\n",
    "        output.write(\"NULL\")\n",
    "\n",
    "        output.write(\"\\n\")\n",
    "        print(e)\n",
    "        continue \n",
    "    \n",
    "output.close()\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "python3env",
   "language": "python",
   "name": "python3env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
